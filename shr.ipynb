{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c55fba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\sreeh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: numpy<3,>=1.25.2 in c:\\users\\sreeh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy<2,>=1.11.4 in c:\\users\\sreeh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.4.2 in c:\\users\\sreeh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib<2,>=1.2.0 in c:\\users\\sreeh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in c:\\users\\sreeh\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32919916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Data loaded successfully.\n",
      "Cleaning data and defining features (X) and target (y)...\n",
      "Splitting data into 80% train and 20% validation sets...\n",
      "Defining preprocessing pipelines...\n",
      "\n",
      "--- Building Full Pipeline with SMOTE ---\n",
      "\n",
      "--- Training Model with SMOTE ---\n",
      "Model training complete.\n",
      "\n",
      "--- Model Evaluation on Validation Set ---\n",
      "Accuracy: 0.7909\n",
      "--------------------------------------------------\n",
      "ROC-AUC Score: 0.7114\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[9555 2162]\n",
      " [ 464  377]]\n",
      "--------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.95      0.82      0.88     11717\n",
      "  failed (1)       0.15      0.45      0.22       841\n",
      "\n",
      "    accuracy                           0.79     12558\n",
      "   macro avg       0.55      0.63      0.55     12558\n",
      "weighted avg       0.90      0.79      0.84     12558\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# --- Import new tools for Strategy 1 ---\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading train.csv...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found.\")\n",
    "    # In a real script, you might exit here\n",
    "    # exit() \n",
    "else:\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- 2. Basic Cleaning & Define X/y ---\n",
    "    print(\"Cleaning data and defining features (X) and target (y)...\")\n",
    "    \n",
    "    cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop_existing)\n",
    "    \n",
    "    df = df.dropna(subset=['status_label'])\n",
    "\n",
    "    target = 'status_label'\n",
    "    y = df[target].map({'alive': 0, 'failed': 1})\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # --- 3. Split Data into Training and Validation Sets ---\n",
    "    print(\"Splitting data into 80% train and 20% validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y  # Crucial for imbalanced data\n",
    "    )\n",
    "\n",
    "    # --- 4. Define Preprocessing Pipelines ---\n",
    "    print(\"Defining preprocessing pipelines...\")\n",
    "    \n",
    "    numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "    categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 5. Define the FULL Pipeline (Preprocessor + SMOTE + Model) ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Building Full Pipeline with SMOTE ---\")\n",
    "    \n",
    "    # Define the model. Note we REMOVED class_weight='balanced'\n",
    "    # SMOTE will handle the imbalance instead.\n",
    "    model = RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        # class_weight='balanced', # <-- REMOVED\n",
    "        n_estimators=150,      # Number of trees in the forest\n",
    "        max_depth=10,          # Limits the depth of each tree\n",
    "        n_jobs=-1              # Use all available CPU cores\n",
    "    )\n",
    "    \n",
    "    # Create the imbalanced-learn pipeline\n",
    "    # This chains the preprocessor, the SMOTE sampler, and the model\n",
    "    # SMOTE will *only* be applied during .fit() and *only* to the training data\n",
    "    full_pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', SMOTE(random_state=42)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 6. Train the Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Training Model with SMOTE ---\")\n",
    "    \n",
    "    # Train the entire pipeline on the *raw* training data.\n",
    "    # The pipeline handles all preprocessing and sampling internally.\n",
    "    full_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- 7. Evaluate the Model ---\n",
    "    print(\"\\n--- Model Evaluation on Validation Set ---\")\n",
    "    \n",
    "    # Predict on the *raw* validation data.\n",
    "    # The pipeline will automatically apply the preprocessor (but not SMOTE)\n",
    "    y_pred = full_pipeline.predict(X_val)\n",
    "    \n",
    "    # Get prediction probabilities for the 'failed' class (class 1)\n",
    "    y_pred_proba = full_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- Print Metrics ---\n",
    "    \n",
    "    # Accuracy\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # ROC-AUC Score\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8be784a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Data loaded successfully.\n",
      "Cleaning data and defining features (X) and target (y)...\n",
      "Splitting data into 80% train and 20% validation sets...\n",
      "Defining preprocessing pipelines...\n",
      "\n",
      "--- Building Full Pipeline for GridSearchCV ---\n",
      "\n",
      "--- Starting Hyperparameter Tuning (GridSearchCV) ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "Tuning complete.\n",
      "Best parameters found: {'model__max_depth': 20, 'model__min_samples_leaf': 1, 'model__n_estimators': 100}\n",
      "Best cross-validation F1-macro score: 0.5852\n",
      "\n",
      "--- Model Evaluation of Best Model on Validation Set ---\n",
      "Accuracy: 0.8824\n",
      "--------------------------------------------------\n",
      "ROC-AUC Score: 0.7680\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[10792   925]\n",
      " [  552   289]]\n",
      "--------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.95      0.92      0.94     11717\n",
      "  failed (1)       0.24      0.34      0.28       841\n",
      "\n",
      "    accuracy                           0.88     12558\n",
      "   macro avg       0.59      0.63      0.61     12558\n",
      "weighted avg       0.90      0.88      0.89     12558\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # Import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline # <-- Make sure this is imported\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# --- Import imblearn tools ---\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading train.csv...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found.\")\n",
    "    # exit() \n",
    "else:\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- 2. Basic Cleaning & Define X/y ---\n",
    "    print(\"Cleaning data and defining features (X) and target (y)...\")\n",
    "    \n",
    "    cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop_existing)\n",
    "    \n",
    "    df = df.dropna(subset=['status_label'])\n",
    "\n",
    "    target = 'status_label'\n",
    "    y = df[target].map({'alive': 0, 'failed': 1})\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # --- 3. Split Data into Training and Validation Sets ---\n",
    "    print(\"Splitting data into 80% train and 20% validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    # --- 4. Define Preprocessing Pipelines ---\n",
    "    print(\"Defining preprocessing pipelines...\")\n",
    "    \n",
    "    numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "    categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 5. Define the FULL Pipeline and Parameter Grid ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Building Full Pipeline for GridSearchCV ---\")\n",
    "    \n",
    "    # Define the model (we'll set params in the grid)\n",
    "    model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "    \n",
    "    # Create the full pipeline\n",
    "    full_pipeline = ImbPipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', SMOTE(random_state=42)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    # --- Define the Parameter Grid ---\n",
    "    # We prefix parameters with 'model__' to tell the pipeline\n",
    "    # to apply them to the 'model' step.\n",
    "    # NOTE: This is a small grid to run quickly. \n",
    "    # For a real search, you'd try more values.\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [100, 200],      # Number of trees\n",
    "        'model__max_depth': [10, 20],           # Max depth of trees\n",
    "        'model__min_samples_leaf': [1, 5]       # Min samples at a leaf node\n",
    "        # 'sampler__k_neighbors': [3, 5]        # You can even tune SMOTE\n",
    "    }\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 6. Set up and Run GridSearchCV ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Hyperparameter Tuning (GridSearchCV) ---\")\n",
    "    \n",
    "    # Set up the Grid Search\n",
    "    # We optimize for 'f1_macro' (average F1 of both classes)\n",
    "    # cv=3 is a 3-fold cross-validation.\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=full_pipeline, \n",
    "        param_grid=param_grid, \n",
    "        scoring='f1_macro', # <-- Optimize for F1-score!\n",
    "        cv=3, \n",
    "        n_jobs=-1,      # Use all cores (can be slow)\n",
    "        verbose=2       # Shows progress\n",
    "    )\n",
    "    \n",
    "    # Train the grid search\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nTuning complete.\")\n",
    "    print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "    print(f\"Best cross-validation F1-macro score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 7. Evaluate the BEST Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Model Evaluation of Best Model on Validation Set ---\")\n",
    "    \n",
    "    # 'grid_search' object now contains the best model found\n",
    "    best_model = grid_search.best_estimator_ \n",
    "\n",
    "    # Predict using the best model\n",
    "    y_pred = best_model.predict(X_val)\n",
    "    y_pred_proba = best_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- Print Metrics ---\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "723fc5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Data loaded successfully.\n",
      "Cleaning data and defining features (X) and target (y)...\n",
      "Splitting data into 80% train and 20% validation sets...\n",
      "Defining preprocessing pipelines...\n",
      "\n",
      "Calculated scale_pos_weight for XGBoost: 13.94\n",
      "\n",
      "--- Starting Hyperparameter Tuning for XGBoost ---\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "\n",
      "Tuning complete.\n",
      "Best XGBoost parameters found: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__n_estimators': 200}\n",
      "Best cross-validation F1-macro score: 0.6673\n",
      "\n",
      "--- Model Evaluation of Best XGBoost Model on Validation Set ---\n",
      "Accuracy: 0.9137\n",
      "--------------------------------------------------\n",
      "ROC-AUC Score: 0.8466\n",
      "--------------------------------------------------\n",
      "Confusion Matrix:\n",
      "[[11077   640]\n",
      " [  444   397]]\n",
      "--------------------------------------------------\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.95      0.95     11717\n",
      "  failed (1)       0.38      0.47      0.42       841\n",
      "\n",
      "    accuracy                           0.91     12558\n",
      "   macro avg       0.67      0.71      0.69     12558\n",
      "weighted avg       0.92      0.91      0.92     12558\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # Import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline # <-- We use the standard pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score\n",
    ")\n",
    "\n",
    "# --- Import the new model ---\n",
    "import xgboost as xgb\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading train.csv...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found.\")\n",
    "    # exit() \n",
    "else:\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- 2. Basic Cleaning & Define X/y ---\n",
    "    print(\"Cleaning data and defining features (X) and target (y)...\")\n",
    "    \n",
    "    cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop_existing)\n",
    "    \n",
    "    df = df.dropna(subset=['status_label'])\n",
    "\n",
    "    target = 'status_label'\n",
    "    y = df[target].map({'alive': 0, 'failed': 1})\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # --- 3. Split Data into Training and Validation Sets ---\n",
    "    print(\"Splitting data into 80% train and 20% validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    # --- 4. Define Preprocessing Pipelines ---\n",
    "    print(\"Defining preprocessing pipelines...\")\n",
    "    \n",
    "    numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "    categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 5. Calculate scale_pos_weight & Define XGBoost Pipeline ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    # Calculate scale_pos_weight for XGBoost\n",
    "    # This is the ratio of (count of 'alive') / (count of 'failed')\n",
    "    # We calculate it *only* on the y_train set\n",
    "    scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "    print(f\"\\nCalculated scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n",
    "\n",
    "    # Define the XGBoost model, passing in the imbalance parameter\n",
    "    model_xgb = xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight, # <-- This handles imbalance\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss' # Suppresses a warning\n",
    "    )\n",
    "    \n",
    "    # Create a *standard* sklearn pipeline (NO SMOTE)\n",
    "    full_pipeline_xgb = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model_xgb)\n",
    "    ])\n",
    "\n",
    "    # --- Define the Parameter Grid for XGBoost ---\n",
    "    # Note: 'learning_rate' is a key parameter for boosting models\n",
    "    param_grid_xgb = {\n",
    "        'model__n_estimators': [100, 200],      # Number of trees\n",
    "        'model__max_depth': [5, 10],            # Max depth of trees\n",
    "        'model__learning_rate': [0.1, 0.05]     # Step size shrinkage\n",
    "    }\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 6. Set up and Run GridSearchCV for XGBoost ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Hyperparameter Tuning for XGBoost ---\")\n",
    "    \n",
    "    grid_search_xgb = GridSearchCV(\n",
    "        estimator=full_pipeline_xgb, \n",
    "        param_grid=param_grid_xgb, \n",
    "        scoring='f1_macro', # <-- Still optimizing for F1\n",
    "        cv=3, \n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Train the grid search on the raw training data\n",
    "    grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nTuning complete.\")\n",
    "    print(f\"Best XGBoost parameters found: {grid_search_xgb.best_params_}\")\n",
    "    print(f\"Best cross-validation F1-macro score: {grid_search_xgb.best_score_:.4f}\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 7. Evaluate the BEST XGBoost Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Model Evaluation of Best XGBoost Model on Validation Set ---\")\n",
    "    \n",
    "    best_model_xgb = grid_search_xgb.best_estimator_ \n",
    "\n",
    "    # Predict using the best model\n",
    "    y_pred = best_model_xgb.predict(X_val)\n",
    "    y_pred_proba = best_model_xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- Print Metrics ---\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f536c90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Data loaded successfully.\n",
      "Cleaning data and defining features (X) and target (y)...\n",
      "Splitting data into 80% train and 20% validation sets...\n",
      "Defining preprocessing pipelines...\n",
      "\n",
      "Calculated scale_pos_weight for XGBoost: 13.94\n",
      "Defining best XGBoost model...\n",
      "\n",
      "--- Training Best XGBoost Model ---\n",
      "Training complete.\n",
      "\n",
      "--- Model Evaluation with Default 0.5 Threshold ---\n",
      "Accuracy: 0.9137\n",
      "ROC-AUC Score: 0.8466\n",
      "Confusion Matrix:\n",
      "[[11077   640]\n",
      " [  444   397]]\n",
      "Classification Report (Default Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.95      0.95     11717\n",
      "  failed (1)       0.38      0.47      0.42       841\n",
      "\n",
      "    accuracy                           0.91     12558\n",
      "   macro avg       0.67      0.71      0.69     12558\n",
      "weighted avg       0.92      0.91      0.92     12558\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Strategy 4: Finding Optimal Threshold ---\n",
      "Best F1-Score found: 0.4285\n",
      "Optimal Threshold: 0.5278\n",
      "\n",
      "--- Model Evaluation with Optimal Threshold ---\n",
      "Accuracy: 0.9201\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Optimal Threshold):\n",
      "[[11179   538]\n",
      " [  465   376]]\n",
      "--------------------------------------------------\n",
      "Classification Report (Optimal Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.95      0.96     11717\n",
      "  failed (1)       0.41      0.45      0.43       841\n",
      "\n",
      "    accuracy                           0.92     12558\n",
      "   macro avg       0.69      0.70      0.69     12558\n",
      "weighted avg       0.92      0.92      0.92     12558\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,  # <-- For threshold tuning\n",
    "    f1_score                 # <-- For threshold tuning\n",
    ")\n",
    "\n",
    "# --- Import XGBoost ---\n",
    "import xgboost as xgb\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading train.csv...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found.\")\n",
    "    # exit() \n",
    "else:\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- 2. Basic Cleaning & Define X/y ---\n",
    "    print(\"Cleaning data and defining features (X) and target (y)...\")\n",
    "    \n",
    "    cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop_existing)\n",
    "    \n",
    "    df = df.dropna(subset=['status_label'])\n",
    "\n",
    "    target = 'status_label'\n",
    "    y = df[target].map({'alive': 0, 'failed': 1})\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # --- 3. Split Data into Training and Validation Sets ---\n",
    "    print(\"Splitting data into 80% train and 20% validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    # --- 4. Define Preprocessing Pipelines ---\n",
    "    print(\"Defining preprocessing pipelines...\")\n",
    "    \n",
    "    numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "    categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 5. Define and Train the BEST XGBoost Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    # Calculate scale_pos_weight\n",
    "    scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "    print(f\"\\nCalculated scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n",
    "\n",
    "    # Define the XGBoost model with the BEST parameters from Strategy 3\n",
    "    print(\"Defining best XGBoost model...\")\n",
    "    best_model_xgb = xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss',\n",
    "        learning_rate=0.1,  # <-- Best param\n",
    "        max_depth=10,       # <-- Best param\n",
    "        n_estimators=200    # <-- Best param\n",
    "    )\n",
    "    \n",
    "    # Create the *standard* sklearn pipeline\n",
    "    full_pipeline_xgb = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', best_model_xgb)\n",
    "    ])\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 6. Train the Best Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Training Best XGBoost Model ---\")\n",
    "    full_pipeline_xgb.fit(X_train, y_train)\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 7. Evaluation with Default Threshold (0.5) ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Model Evaluation with Default 0.5 Threshold ---\")\n",
    "    \n",
    "    # Get standard predictions and probabilities\n",
    "    y_pred_default = full_pipeline_xgb.predict(X_val)\n",
    "    y_pred_proba = full_pipeline_xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_default):.4f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred_default))\n",
    "    print(\"Classification Report (Default Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_default, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- STRATEGY 4: Find and Apply Optimal Threshold ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Strategy 4: Finding Optimal Threshold ---\")\n",
    "\n",
    "    # We already have the probabilities from the step above (y_pred_proba)\n",
    "    \n",
    "    # Calculate precision, recall, and thresholds\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "\n",
    "    # Calculate F1-score for all thresholds\n",
    "    # We add a small epsilon (1e-9) to avoid division by zero\n",
    "    f1_scores = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "    \n",
    "    # Find the threshold that gives the maximum F1-score\n",
    "    # Note: thresholds array is 1 shorter than precision/recall,\n",
    "    # so we index f1_scores up to the length of thresholds.\n",
    "    best_f1_idx = np.argmax(f1_scores[:-1]) # Get index of best F1\n",
    "    best_threshold = thresholds[best_f1_idx]\n",
    "    best_f1 = f1_scores[best_f1_idx]\n",
    "\n",
    "    print(f\"Best F1-Score found: {best_f1:.4f}\")\n",
    "    print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    # --- Evaluate with the NEW threshold ---\n",
    "    print(\"\\n--- Model Evaluation with Optimal Threshold ---\")\n",
    "\n",
    "    # Get new predictions based on the optimal threshold\n",
    "    y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_optimal):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Confusion Matrix (Optimal Threshold):\")\n",
    "    print(confusion_matrix(y_val, y_pred_optimal))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Classification Report (Optimal Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_optimal, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13835b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Data loaded successfully.\n",
      "Cleaning data and defining features (X) and target (y)...\n",
      "Splitting data into 80% train and 20% validation sets...\n",
      "Defining preprocessing pipelines...\n",
      "\n",
      "Calculated scale_pos_weight for XGBoost: 13.94\n",
      "\n",
      "--- Starting EXPANDED Hyperparameter Tuning for XGBoost (Strategy 5) ---\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "Tuning complete.\n",
      "Best XGBoost parameters found: {'model__learning_rate': 0.1, 'model__max_depth': 10, 'model__min_child_weight': 5, 'model__n_estimators': 300}\n",
      "Best cross-validation F1-macro score: 0.6735\n",
      "\n",
      "--- Model Evaluation of NEW Best XGBoost Model (Default 0.5 Threshold) ---\n",
      "Accuracy: 0.9274\n",
      "ROC-AUC Score: 0.8572\n",
      "Classification Report (Default Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.96      0.96     11717\n",
      "  failed (1)       0.45      0.42      0.43       841\n",
      "\n",
      "    accuracy                           0.93     12558\n",
      "   macro avg       0.71      0.69      0.70     12558\n",
      "weighted avg       0.92      0.93      0.93     12558\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Applying Optimal Threshold Tuning to NEW Best Model ---\n",
      "Best F1-Score found: 0.4378\n",
      "Optimal Threshold: 0.4307\n",
      "\n",
      "--- Final Model Evaluation (New Model + Optimal Threshold) ---\n",
      "Accuracy: 0.9172\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Optimal Threshold):\n",
      "[[11113   604]\n",
      " [  436   405]]\n",
      "--------------------------------------------------\n",
      "Classification Report (Optimal Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.95      0.96     11717\n",
      "  failed (1)       0.40      0.48      0.44       841\n",
      "\n",
      "    accuracy                           0.92     12558\n",
      "   macro avg       0.68      0.72      0.70     12558\n",
      "weighted avg       0.92      0.92      0.92     12558\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV # Import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score,\n",
    "    precision_recall_curve, # For final threshold tuning\n",
    "    f1_score                # For final threshold tuning\n",
    ")\n",
    "\n",
    "# --- Import the new model ---\n",
    "import xgboost as xgb\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading train.csv...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found.\")\n",
    "    # exit() \n",
    "else:\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- 2. Basic Cleaning & Define X/y ---\n",
    "    print(\"Cleaning data and defining features (X) and target (y)...\")\n",
    "    \n",
    "    cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop_existing)\n",
    "    \n",
    "    df = df.dropna(subset=['status_label'])\n",
    "\n",
    "    target = 'status_label'\n",
    "    y = df[target].map({'alive': 0, 'failed': 1})\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # --- 3. Split Data into Training and Validation Sets ---\n",
    "    print(\"Splitting data into 80% train and 20% validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    # --- 4. Define Preprocessing Pipelines ---\n",
    "    print(\"Defining preprocessing pipelines...\")\n",
    "    \n",
    "    numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "    categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 5. Calculate scale_pos_weight & Define XGBoost Pipeline ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    # Calculate scale_pos_weight for XGBoost\n",
    "    scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "    print(f\"\\nCalculated scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n",
    "\n",
    "    # Define the XGBoost model\n",
    "    model_xgb = xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight, # <-- Handles imbalance\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss' \n",
    "    )\n",
    "    \n",
    "    # Create a *standard* sklearn pipeline (NO SMOTE)\n",
    "    full_pipeline_xgb = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model_xgb)\n",
    "    ])\n",
    "\n",
    "    # --- Define the EXPANDED Parameter Grid for XGBoost ---\n",
    "    # This grid is more focused based on our last results.\n",
    "    param_grid_xgb_expanded = {\n",
    "        'model__n_estimators': [200, 300],      # Test higher estimators\n",
    "        'model__max_depth': [8, 10, 12],        # Explore around the previous best (10)\n",
    "        'model__learning_rate': [0.1, 0.05],    # 0.1 was good, 0.05 is also common\n",
    "        'model__min_child_weight': [1, 5]       # New param to control overfitting\n",
    "    }\n",
    "    # Total fits: 2 * 3 * 2 * 2 = 24 candidates. With cv=3, this is 72 model fits.\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 6. Set up and Run EXPANDED GridSearchCV for XGBoost ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting EXPANDED Hyperparameter Tuning for XGBoost (Strategy 5) ---\")\n",
    "    \n",
    "    grid_search_xgb = GridSearchCV(\n",
    "        estimator=full_pipeline_xgb, \n",
    "        param_grid=param_grid_xgb_expanded, \n",
    "        scoring='f1_macro', # <-- Still optimizing for F1\n",
    "        cv=3, \n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Train the grid search on the raw training data\n",
    "    grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nTuning complete.\")\n",
    "    print(f\"Best XGBoost parameters found: {grid_search_xgb.best_params_}\")\n",
    "    print(f\"Best cross-validation F1-macro score: {grid_search_xgb.best_score_:.4f}\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 7. Evaluate the NEW BEST XGBoost Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Model Evaluation of NEW Best XGBoost Model (Default 0.5 Threshold) ---\")\n",
    "    \n",
    "    best_model_xgb = grid_search_xgb.best_estimator_ \n",
    "\n",
    "    # Predict using the new best model\n",
    "    y_pred_default = best_model_xgb.predict(X_val)\n",
    "    y_pred_proba = best_model_xgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- Print Metrics (Default Threshold) ---\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_default):.4f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(\"Classification Report (Default Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_default, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 8. Apply Optimal Threshold Tuning to the NEW Best Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Applying Optimal Threshold Tuning to NEW Best Model ---\")\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "    f1_scores = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "    \n",
    "    best_f1_idx = np.argmax(f1_scores[:-1])\n",
    "    best_threshold = thresholds[best_f1_idx]\n",
    "    best_f1 = f1_scores[best_f1_idx]\n",
    "\n",
    "    print(f\"Best F1-Score found: {best_f1:.4f}\")\n",
    "    print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    # --- Evaluate with the NEW threshold ---\n",
    "    print(\"\\n--- Final Model Evaluation (New Model + Optimal Threshold) ---\")\n",
    "\n",
    "    y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_optimal):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Confusion Matrix (Optimal Threshold):\")\n",
    "    print(confusion_matrix(y_val, y_pred_optimal))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Classification Report (Optimal Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_optimal, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaf61d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Data loaded successfully.\n",
      "Cleaning data and defining features (X) and target (y)...\n",
      "Splitting data into 80% train and 20% validation sets...\n",
      "Defining preprocessing pipelines...\n",
      "\n",
      "Defining LightGBM model pipeline...\n",
      "Grid search will test 24 candidates.\n",
      "\n",
      "--- Starting Hyperparameter Tuning for LightGBM ---\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "\n",
      "Tuning complete.\n",
      "Best LightGBM parameters found: {'model__learning_rate': 0.1, 'model__min_child_samples': 10, 'model__n_estimators': 300, 'model__num_leaves': 70}\n",
      "Best cross-validation F1-macro score: 0.6716\n",
      "\n",
      "--- Model Evaluation of Best LightGBM Model (Default 0.5 Threshold) ---\n",
      "Accuracy: 0.9155\n",
      "ROC-AUC Score: 0.8613\n",
      "Classification Report (Default Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.95      0.95     11717\n",
      "  failed (1)       0.39      0.44      0.41       841\n",
      "\n",
      "    accuracy                           0.92     12558\n",
      "   macro avg       0.67      0.70      0.68     12558\n",
      "weighted avg       0.92      0.92      0.92     12558\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Applying Optimal Threshold Tuning to Best LightGBM Model ---\n",
      "Best F1-Score found: 0.4290\n",
      "Optimal Threshold: 0.6293\n",
      "\n",
      "--- Final Model Evaluation (LGBM + Optimal Threshold) ---\n",
      "Accuracy: 0.9353\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Optimal Threshold):\n",
      "[[11441   276]\n",
      " [  536   305]]\n",
      "--------------------------------------------------\n",
      "Classification Report (Optimal Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.98      0.97     11717\n",
      "  failed (1)       0.52      0.36      0.43       841\n",
      "\n",
      "    accuracy                           0.94     12558\n",
      "   macro avg       0.74      0.67      0.70     12558\n",
      "weighted avg       0.93      0.94      0.93     12558\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sreeh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sreeh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# --- Import the new model ---\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading train.csv...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found.\")\n",
    "    # exit() \n",
    "else:\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- 2. Basic Cleaning & Define X/y ---\n",
    "    print(\"Cleaning data and defining features (X) and target (y)...\")\n",
    "    \n",
    "    cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop_existing)\n",
    "    \n",
    "    df = df.dropna(subset=['status_label'])\n",
    "\n",
    "    target = 'status_label'\n",
    "    y = df[target].map({'alive': 0, 'failed': 1})\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # --- 3. Split Data into Training and Validation Sets ---\n",
    "    print(\"Splitting data into 80% train and 20% validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    # --- 4. Define Preprocessing Pipelines ---\n",
    "    print(\"Defining preprocessing pipelines...\")\n",
    "    \n",
    "    numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "    categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 5. Define LightGBM Pipeline ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\nDefining LightGBM model pipeline...\")\n",
    "    \n",
    "    # Define the LightGBM model\n",
    "    # We use class_weight='balanced' to handle imbalance\n",
    "    model_lgb = lgb.LGBMClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced', # <-- This handles imbalance\n",
    "        n_jobs=-1,\n",
    "        verbose=-1 # Suppresses LightGBM's internal warnings\n",
    "    )\n",
    "    \n",
    "    # Create a *standard* sklearn pipeline\n",
    "    full_pipeline_lgb = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model_lgb)\n",
    "    ])\n",
    "\n",
    "    # --- Define the Parameter Grid for LightGBM ---\n",
    "    # Note: 'num_leaves' is a key parameter for LGBM, often\n",
    "    # tuned instead of 'max_depth'.\n",
    "    param_grid_lgb = {\n",
    "        'model__n_estimators': [200, 300],\n",
    "        'model__learning_rate': [0.1, 0.05],\n",
    "        'model__num_leaves': [31, 50, 70],      # Default is 31\n",
    "        'model__min_child_samples': [10, 20]  # Equivalent to min_child_weight\n",
    "    }\n",
    "    # Total fits: 2 * 2 * 3 * 2 = 24 candidates\n",
    "    print(f\"Grid search will test {2*2*3*2} candidates.\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 6. Set up and Run GridSearchCV for LightGBM ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Starting Hyperparameter Tuning for LightGBM ---\")\n",
    "    \n",
    "    grid_search_lgb = GridSearchCV(\n",
    "        estimator=full_pipeline_lgb, \n",
    "        param_grid=param_grid_lgb, \n",
    "        scoring='f1_macro', # <-- Still optimizing for F1\n",
    "        cv=3, \n",
    "        n_jobs=-1,\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # Train the grid search on the raw training data\n",
    "    grid_search_lgb.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nTuning complete.\")\n",
    "    print(f\"Best LightGBM parameters found: {grid_search_lgb.best_params_}\")\n",
    "    print(f\"Best cross-validation F1-macro score: {grid_search_lgb.best_score_:.4f}\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 7. Evaluate the BEST LightGBM Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Model Evaluation of Best LightGBM Model (Default 0.5 Threshold) ---\")\n",
    "    \n",
    "    best_model_lgb = grid_search_lgb.best_estimator_ \n",
    "\n",
    "    # Predict using the new best model\n",
    "    y_pred_default = best_model_lgb.predict(X_val)\n",
    "    y_pred_proba = best_model_lgb.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- Print Metrics (Default Threshold) ---\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_default):.4f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(\"Classification Report (Default Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_default, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 8. Apply Optimal Threshold Tuning to the NEW Best Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Applying Optimal Threshold Tuning to Best LightGBM Model ---\")\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "    f1_scores = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "    \n",
    "    best_f1_idx = np.argmax(f1_scores[:-1])\n",
    "    best_threshold = thresholds[best_f1_idx]\n",
    "    best_f1 = f1_scores[best_f1_idx]\n",
    "\n",
    "    print(f\"Best F1-Score found: {best_f1:.4f}\")\n",
    "    print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    # --- Evaluate with the NEW threshold ---\n",
    "    print(\"\\n--- Final Model Evaluation (LGBM + Optimal Threshold) ---\")\n",
    "\n",
    "    y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_optimal):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Confusion Matrix (Optimal Threshold):\")\n",
    "    print(confusion_matrix(y_val, y_pred_optimal))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Classification Report (Optimal Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_optimal, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3cec145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Data loaded successfully.\n",
      "Cleaning data and defining features (X) and target (y)...\n",
      "Splitting data into 80% train and 20% validation sets...\n",
      "Defining preprocessing pipelines...\n",
      "\n",
      "Calculated scale_pos_weight for XGBoost: 13.94\n",
      "\n",
      "Defining Stacking Classifier pipeline...\n",
      "\n",
      "--- Training Stacking Classifier ---\n",
      "Training complete.\n",
      "\n",
      "--- Model Evaluation of Stacking Model (Default 0.5 Threshold) ---\n",
      "Accuracy: 0.9398\n",
      "ROC-AUC Score: 0.8683\n",
      "Classification Report (Default Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.95      0.98      0.97     11717\n",
      "  failed (1)       0.59      0.32      0.42       841\n",
      "\n",
      "    accuracy                           0.94     12558\n",
      "   macro avg       0.77      0.65      0.69     12558\n",
      "weighted avg       0.93      0.94      0.93     12558\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Applying Optimal Threshold Tuning to Stacking Model ---\n",
      "Best F1-Score found: 0.4501\n",
      "Optimal Threshold: 0.2858\n",
      "\n",
      "--- Final Model Evaluation (Stacking Model + Optimal Threshold) ---\n",
      "Accuracy: 0.9245\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Optimal Threshold):\n",
      "[[11222   495]\n",
      " [  453   388]]\n",
      "--------------------------------------------------\n",
      "Classification Report (Optimal Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.96      0.96     11717\n",
      "  failed (1)       0.44      0.46      0.45       841\n",
      "\n",
      "    accuracy                           0.92     12558\n",
      "   macro avg       0.70      0.71      0.70     12558\n",
      "weighted avg       0.93      0.92      0.93     12558\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sreeh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sreeh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# --- Import Ensemble Tools ---\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression # Our \"meta-model\"\n",
    "\n",
    "# --- Import Base Models ---\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading train.csv...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found.\")\n",
    "    # exit() \n",
    "else:\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- 2. Basic Cleaning & Define X/y ---\n",
    "    print(\"Cleaning data and defining features (X) and target (y)...\")\n",
    "    \n",
    "    cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop_existing)\n",
    "    \n",
    "    df = df.dropna(subset=['status_label'])\n",
    "\n",
    "    target = 'status_label'\n",
    "    y = df[target].map({'alive': 0, 'failed': 1})\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # --- 3. Split Data into Training and Validation Sets ---\n",
    "    print(\"Splitting data into 80% train and 20% validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    # --- 4. Define Preprocessing Pipelines ---\n",
    "    print(\"Defining preprocessing pipelines...\")\n",
    "    \n",
    "    numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "    categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # --- 5. Calculate scale_pos_weight for XGBoost ---\n",
    "    scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "    print(f\"\\nCalculated scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 6. Define the Stacking Classifier Pipeline ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\nDefining Stacking Classifier pipeline...\")\n",
    "    \n",
    "    # --- Define our best models with their optimal parameters ---\n",
    "    \n",
    "    best_model_xgb = xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=10,\n",
    "        min_child_weight=5,\n",
    "        n_estimators=300,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    best_model_lgb = lgb.LGBMClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        learning_rate=0.1,\n",
    "        min_child_samples=10,\n",
    "        n_estimators=300,\n",
    "        num_leaves=70,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # --- Create the list of base estimators ---\n",
    "    estimators = [\n",
    "        ('xgb', best_model_xgb),\n",
    "        ('lgbm', best_model_lgb)\n",
    "    ]\n",
    "    \n",
    "    # --- Create the Stacking Classifier ---\n",
    "    # It will use Logistic Regression to combine the outputs\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=3, # Cross-validation for training the meta-model\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # --- Create the FULL pipeline (Preprocessor + Stacker) ---\n",
    "    full_pipeline_stack = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('stacker', stacking_model)\n",
    "    ])\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 7. Train the Stacking Classifier ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Training Stacking Classifier ---\")\n",
    "    # This will take some time as it's training multiple models\n",
    "    \n",
    "    full_pipeline_stack.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 8. Evaluate the Stacking Classifier ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Model Evaluation of Stacking Model (Default 0.5 Threshold) ---\")\n",
    "    \n",
    "    y_pred_default = full_pipeline_stack.predict(X_val)\n",
    "    y_pred_proba = full_pipeline_stack.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- Print Metrics (Default Threshold) ---\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_default):.4f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(\"Classification Report (Default Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_default, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 9. Apply Optimal Threshold Tuning to the Stacking Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Applying Optimal Threshold Tuning to Stacking Model ---\")\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "    f1_scores = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "    \n",
    "    best_f1_idx = np.argmax(f1_scores[:-1])\n",
    "    best_threshold = thresholds[best_f1_idx]\n",
    "    best_f1 = f1_scores[best_f1_idx]\n",
    "\n",
    "    print(f\"Best F1-Score found: {best_f1:.4f}\")\n",
    "    print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    # --- Evaluate with the NEW threshold ---\n",
    "    print(\"\\n--- Final Model Evaluation (Stacking Model + Optimal Threshold) ---\")\n",
    "\n",
    "    y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_optimal):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Confusion Matrix (Optimal Threshold):\")\n",
    "    print(confusion_matrix(y_val, y_pred_optimal))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Classification Report (Optimal Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_optimal, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "062bf929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train.csv...\n",
      "Data loaded successfully.\n",
      "Cleaning data and defining features (X) and target (y)...\n",
      "Splitting data into 80% train and 20% validation sets...\n",
      "Defining preprocessing pipelines...\n",
      "\n",
      "Calculated scale_pos_weight for XGBoost: 13.94\n",
      "\n",
      "Defining Stacking Classifier pipeline with XGB, LGBM, and CatBoost...\n",
      "\n",
      "--- Training Stacking Classifier (XGB+LGBM+CAT) ---\n",
      "Training complete.\n",
      "\n",
      "--- Model Evaluation of Stacking Model (Default 0.5 Threshold) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sreeh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\sreeh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9398\n",
      "ROC-AUC Score: 0.8716\n",
      "Classification Report (Default Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.95      0.99      0.97     11717\n",
      "  failed (1)       0.60      0.30      0.40       841\n",
      "\n",
      "    accuracy                           0.94     12558\n",
      "   macro avg       0.78      0.64      0.68     12558\n",
      "weighted avg       0.93      0.94      0.93     12558\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- Applying Optimal Threshold Tuning to Stacking Model ---\n",
      "Best F1-Score found: 0.4467\n",
      "Optimal Threshold: 0.2600\n",
      "\n",
      "--- Final Model Evaluation (Stacking Model + Optimal Threshold) ---\n",
      "Accuracy: 0.9189\n",
      "--------------------------------------------------\n",
      "Confusion Matrix (Optimal Threshold):\n",
      "[[11129   588]\n",
      " [  430   411]]\n",
      "--------------------------------------------------\n",
      "Classification Report (Optimal Threshold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   alive (0)       0.96      0.95      0.96     11717\n",
      "  failed (1)       0.41      0.49      0.45       841\n",
      "\n",
      "    accuracy                           0.92     12558\n",
      "   macro avg       0.69      0.72      0.70     12558\n",
      "weighted avg       0.93      0.92      0.92     12558\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "# --- Import Ensemble Tools ---\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression # Our \"meta-model\"\n",
    "\n",
    "# --- Import Base Models ---\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier # <-- 1. Import CatBoost\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "print(\"Loading train.csv...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: train.csv not found.\")\n",
    "    # exit() \n",
    "else:\n",
    "    print(\"Data loaded successfully.\")\n",
    "\n",
    "    # --- 2. Basic Cleaning & Define X/y ---\n",
    "    print(\"Cleaning data and defining features (X) and target (y)...\")\n",
    "    \n",
    "    cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "    cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "    df = df.drop(columns=cols_to_drop_existing)\n",
    "    \n",
    "    df = df.dropna(subset=['status_label'])\n",
    "\n",
    "    target = 'status_label'\n",
    "    y = df[target].map({'alive': 0, 'failed': 1})\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # --- 3. Split Data into Training and Validation Sets ---\n",
    "    print(\"Splitting data into 80% train and 20% validation sets...\")\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, \n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    # --- 4. Define Preprocessing Pipelines ---\n",
    "    print(\"Defining preprocessing pipelines...\")\n",
    "    \n",
    "    numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "    categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    \n",
    "    # --- 5. Calculate scale_pos_weight for XGBoost ---\n",
    "    scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
    "    print(f\"\\nCalculated scale_pos_weight for XGBoost: {scale_pos_weight:.2f}\")\n",
    "\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 6. Define the Stacking Classifier Pipeline ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\nDefining Stacking Classifier pipeline with XGB, LGBM, and CatBoost...\")\n",
    "    \n",
    "    # --- Define our best models with their optimal parameters ---\n",
    "    \n",
    "    best_model_xgb = xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=10,\n",
    "        min_child_weight=5,\n",
    "        n_estimators=300,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "    best_model_lgb = lgb.LGBMClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        learning_rate=0.1,\n",
    "        min_child_samples=10,\n",
    "        n_estimators=300,\n",
    "        num_leaves=70,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "    \n",
    "    # --- 2. Define the new CatBoost model ---\n",
    "    # We use auto_class_weights to handle imbalance\n",
    "    model_cat = CatBoostClassifier(\n",
    "        random_state=42,\n",
    "        auto_class_weights='Balanced',\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.1,\n",
    "        verbose=0 # Suppress training output\n",
    "    )\n",
    "    \n",
    "    # --- 3. Create the new list of base estimators ---\n",
    "    estimators = [\n",
    "        ('xgb', best_model_xgb),\n",
    "        ('lgbm', best_model_lgb),\n",
    "        ('cat', model_cat) # <-- The new addition\n",
    "    ]\n",
    "    \n",
    "    # --- Create the Stacking Classifier ---\n",
    "    stacking_model = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=LogisticRegression(),\n",
    "        cv=3, # Cross-validation for training the meta-model\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # --- Create the FULL pipeline (Preprocessor + Stacker) ---\n",
    "    full_pipeline_stack = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('stacker', stacking_model)\n",
    "    ])\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 7. Train the Stacking Classifier ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Training Stacking Classifier (XGB+LGBM+CAT) ---\")\n",
    "    # This will take even longer now\n",
    "    \n",
    "    full_pipeline_stack.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Training complete.\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 8. Evaluate the Stacking Classifier ---\n",
    "    # -----------------------------------------------------------------\n",
    "\n",
    "    print(\"\\n--- Model Evaluation of Stacking Model (Default 0.5 Threshold) ---\")\n",
    "    \n",
    "    y_pred_default = full_pipeline_stack.predict(X_val)\n",
    "    y_pred_proba = full_pipeline_stack.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # --- Print Metrics (Default Threshold) ---\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_default):.4f}\")\n",
    "    print(f\"ROC-AUC Score: {roc_auc_score(y_val, y_pred_proba):.4f}\")\n",
    "    print(\"Classification Report (Default Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_default, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # -----------------------------------------------------------------\n",
    "    # --- 9. Apply Optimal Threshold Tuning to the Stacking Model ---\n",
    "    # -----------------------------------------------------------------\n",
    "    \n",
    "    print(\"\\n--- Applying Optimal Threshold Tuning to Stacking Model ---\")\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "    f1_scores = (2 * precision * recall) / (precision + recall + 1e-9)\n",
    "    \n",
    "    best_f1_idx = np.argmax(f1_scores[:-1])\n",
    "    best_threshold = thresholds[best_f1_idx]\n",
    "    best_f1 = f1_scores[best_f1_idx]\n",
    "\n",
    "    print(f\"Best F1-Score found: {best_f1:.4f}\")\n",
    "    print(f\"Optimal Threshold: {best_threshold:.4f}\")\n",
    "\n",
    "    # --- Evaluate with the NEW threshold ---\n",
    "    print(\"\\n--- Final Model Evaluation (Stacking Model + Optimal Threshold) ---\")\n",
    "\n",
    "    y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy_score(y_val, y_pred_optimal):.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Confusion Matrix (Optimal Threshold):\")\n",
    "    print(confusion_matrix(y_val, y_pred_optimal))\n",
    "    print(\"--------------------------------------------------\")\n",
    "    print(\"Classification Report (Optimal Threshold):\")\n",
    "    print(classification_report(y_val, y_pred_optimal, target_names=['alive (0)', 'failed (1)']))\n",
    "    print(\"--------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "483c2d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "  ADVANCED F1-SCORE OPTIMIZATION PIPELINE\n",
      "======================================================================\n",
      "\n",
      "[1/8] Loading data...\n",
      " Data loaded: (62789, 24)\n",
      "\n",
      "[2/8] Data preprocessing...\n",
      " Class distribution: Alive=58586, Failed=4203\n",
      " Imbalance ratio: 13.9:1\n",
      "\n",
      "[3/8] Splitting data...\n",
      " Train: 50231 | Val: 12558\n",
      " Train failed class: 3362 (6.7%)\n",
      "\n",
      "[4/8] Feature engineering...\n",
      " Preprocessing pipeline configured\n",
      "\n",
      "[5/8] Configuring models...\n",
      " Base scale_pos_weight: 13.94\n",
      " Models configured\n",
      "\n",
      "[6/8] Training ensemble models with different strategies...\n",
      "     (This will take several minutes...)\n",
      "\n",
      "   [1/6] BorderlineSMOTE + Enhanced Stacking...\n",
      "        Complete\n",
      "   [2/6] SMOTEENN + Enhanced Stacking...\n",
      "        Complete\n",
      "   [3/6] Hybrid (Undersample + ADASYN) + Stacking...\n",
      "        Complete\n",
      "   [4/6] Weighted Voting (No Resampling)...\n",
      "        Complete\n",
      "   [5/6] SMOTETomek + 3-Model Stacking...\n",
      "        Complete\n",
      "   [6/6] ADASYN + 4-Model Deep Stacking...\n",
      "        Complete\n",
      "\n",
      "[7/8] Evaluating all models...\n",
      "\n",
      "   ===========================================================================\n",
      "   Model                | F1-Score   | Precision  | Recall     | Threshold\n",
      "   ===========================================================================\n",
      "   BorderlineSMOTE      | F1: 0.2692 | P: 0.2167 | R: 0.3555 | Thresh: 0.6576\n",
      "   SMOTEENN             | F1: 0.2954 | P: 0.2327 | R: 0.4043 | Thresh: 0.7371\n",
      "   Hybrid               | F1: 0.2960 | P: 0.2512 | R: 0.3603 | Thresh: 0.7547\n",
      "   WeightedVoting       | F1: 0.3701 | P: 0.3089 | R: 0.4614 | Thresh: 0.7995\n",
      "   SMOTETomek           | F1: 0.2684 | P: 0.2056 | R: 0.3864 | Thresh: 0.6362\n",
      "   ADASYN_Deep          | F1: 0.2527 | P: 0.2332 | R: 0.2759 | Thresh: 0.7738\n",
      "\n",
      "[8/8] Final Results\n",
      "\n",
      "======================================================================\n",
      "  F1-SCORE RANKING\n",
      "======================================================================\n",
      "\n",
      "Rank   Model                  F1         Precision  Recall     ROC-AUC   \n",
      "----------------------------------------------------------------------\n",
      " 1    WeightedVoting         0.3701     0.3089     0.4614     0.8343    \n",
      " 2    Hybrid                 0.2960     0.2512     0.3603     0.7817    \n",
      " 3    SMOTEENN               0.2954     0.2327     0.4043     0.7682    \n",
      "   4    BorderlineSMOTE        0.2692     0.2167     0.3555     0.7425    \n",
      "   5    SMOTETomek             0.2684     0.2056     0.3864     0.7482    \n",
      "   6    ADASYN_Deep            0.2527     0.2332     0.2759     0.7353    \n",
      "\n",
      "======================================================================\n",
      " CHAMPION MODEL: WeightedVoting\n",
      "======================================================================\n",
      "\n",
      " Performance Metrics:\n",
      "   F1-Score:        0.3701\n",
      "   Precision:       0.3089\n",
      "   Recall:          0.4614\n",
      "   Accuracy:        0.8948\n",
      "   ROC-AUC:         0.8343\n",
      "   Optimal Thresh:  0.7995\n",
      "\n",
      " Confusion Matrix:\n",
      "                Predicted\n",
      "              Alive  Failed\n",
      "   Actual Alive  10849    868\n",
      "   Actual Failed   453    388\n",
      "\n",
      " Performance vs Baseline:\n",
      "   Baseline F1:     0.4314\n",
      "   Current F1:      0.3701\n",
      "   Change:          -14.2%\n",
      "\n",
      " Key Insights:\n",
      "    Detected 388 out of 841 failures (46.1% recall)\n",
      "    30.9% of predicted failures were correct\n",
      "    Use threshold = 0.7995 for optimal F1-score\n",
      "\n",
      "======================================================================\n",
      "Pipeline complete! Models ready for production use.\n",
      "======================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix, \n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    f1_score,\n",
    "    make_scorer\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# --- Ensemble Tools ---\n",
    "from sklearn.ensemble import StackingClassifier, VotingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# --- Base Models ---\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================================================\n",
    "# 1. LOAD DATA\n",
    "# ============================================================\n",
    "print(\"=\"*70)\n",
    "print(\"  ADVANCED F1-SCORE OPTIMIZATION PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n[1/8] Loading data...\")\n",
    "try:\n",
    "    df = pd.read_csv('train.csv')\n",
    "    print(f\" Data loaded: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\" Error: train.csv not found.\")\n",
    "    exit()\n",
    "\n",
    "# ============================================================\n",
    "# 2. DATA CLEANING & ANALYSIS\n",
    "# ============================================================\n",
    "print(\"\\n[2/8] Data preprocessing...\")\n",
    "\n",
    "cols_to_drop = ['Unnamed: 0', 'company_name', 'fyear']\n",
    "cols_to_drop_existing = [col for col in cols_to_drop if col in df.columns]\n",
    "df = df.drop(columns=cols_to_drop_existing)\n",
    "df = df.dropna(subset=['status_label'])\n",
    "\n",
    "# Analyze class imbalance\n",
    "class_counts = df['status_label'].value_counts()\n",
    "imbalance_ratio = class_counts['alive'] / class_counts['failed']\n",
    "print(f\" Class distribution: Alive={class_counts['alive']}, Failed={class_counts['failed']}\")\n",
    "print(f\" Imbalance ratio: {imbalance_ratio:.1f}:1\")\n",
    "\n",
    "# Prepare features and target\n",
    "target = 'status_label'\n",
    "y = df[target].map({'alive': 0, 'failed': 1})\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "# ============================================================\n",
    "# 3. TRAIN-VALIDATION SPLIT\n",
    "# ============================================================\n",
    "print(\"\\n[3/8] Splitting data...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f\" Train: {len(y_train)} | Val: {len(y_val)}\")\n",
    "print(f\" Train failed class: {sum(y_train==1)} ({sum(y_train==1)/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================\n",
    "# 4. ENHANCED FEATURE ENGINEERING\n",
    "# ============================================================\n",
    "print(\"\\n[4/8] Feature engineering...\")\n",
    "\n",
    "numerical_features = [f'X{i}' for i in range(1, 19)]\n",
    "categorical_features = ['Division', 'MajorGroup']\n",
    "\n",
    "# Enhanced numerical pipeline with feature selection\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "print(\" Preprocessing pipeline configured\")\n",
    "\n",
    "# ============================================================\n",
    "# 5. ADVANCED MODEL CONFIGURATIONS\n",
    "# ============================================================\n",
    "print(\"\\n[5/8] Configuring models...\")\n",
    "\n",
    "# Calculate optimal class weights\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\" Base scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# XGBoost - Tuned for high recall with controlled precision\n",
    "def get_xgb_model(weight_multiplier=1.0):\n",
    "    return xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        scale_pos_weight=scale_pos_weight * weight_multiplier,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=5,\n",
    "        min_child_weight=1,\n",
    "        n_estimators=1000,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        gamma=0.1,\n",
    "        reg_alpha=1.0,\n",
    "        reg_lambda=2.0,\n",
    "        max_delta_step=1,  # Helps with imbalanced data\n",
    "        n_jobs=-1,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "\n",
    "# LightGBM - Tuned for precision\n",
    "def get_lgb_model():\n",
    "    return lgb.LGBMClassifier(\n",
    "        random_state=42,\n",
    "        class_weight='balanced',\n",
    "        learning_rate=0.02,\n",
    "        min_child_samples=20,\n",
    "        n_estimators=1000,\n",
    "        num_leaves=31,\n",
    "        max_depth=5,\n",
    "        subsample=0.7,\n",
    "        colsample_bytree=0.7,\n",
    "        reg_alpha=1.0,\n",
    "        reg_lambda=2.0,\n",
    "        min_split_gain=0.1,\n",
    "        is_unbalance=True,\n",
    "        n_jobs=-1,\n",
    "        verbose=-1\n",
    "    )\n",
    "\n",
    "# CatBoost - Robust to imbalance\n",
    "def get_cat_model():\n",
    "    return CatBoostClassifier(\n",
    "        random_state=42,\n",
    "        auto_class_weights='Balanced',\n",
    "        n_estimators=1000,\n",
    "        learning_rate=0.02,\n",
    "        depth=5,\n",
    "        l2_leaf_reg=5,\n",
    "        bootstrap_type='Bernoulli',\n",
    "        subsample=0.7,\n",
    "        rsm=0.7,\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "# Random Forest - Different ensemble approach\n",
    "def get_rf_model():\n",
    "    return RandomForestClassifier(\n",
    "        random_state=42,\n",
    "        n_estimators=500,\n",
    "        max_depth=10,\n",
    "        min_samples_split=20,\n",
    "        min_samples_leaf=10,\n",
    "        max_features='sqrt',\n",
    "        class_weight='balanced_subsample',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "print(\" Models configured\")\n",
    "\n",
    "# ============================================================\n",
    "# 6. MULTIPLE TRAINING STRATEGIES\n",
    "# ============================================================\n",
    "print(\"\\n[6/8] Training ensemble models with different strategies...\")\n",
    "print(\"     (This will take several minutes...)\\n\")\n",
    "\n",
    "models = {}\n",
    "strategies_info = []\n",
    "\n",
    "# STRATEGY 1: BorderlineSMOTE (focuses on borderline cases)\n",
    "print(\"   [1/6] BorderlineSMOTE + Enhanced Stacking...\")\n",
    "try:\n",
    "    borderline_smote = BorderlineSMOTE(random_state=42, k_neighbors=7, m_neighbors=10)\n",
    "    stacking_1 = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('xgb', get_xgb_model(1.5)),\n",
    "            ('lgbm', get_lgb_model()),\n",
    "            ('cat', get_cat_model()),\n",
    "            ('rf', get_rf_model())\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(\n",
    "            class_weight='balanced', \n",
    "            max_iter=2000, \n",
    "            C=0.05,\n",
    "            penalty='l2',\n",
    "            solver='saga'\n",
    "        ),\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    models['BorderlineSMOTE'] = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', borderline_smote),\n",
    "        ('stacker', stacking_1)\n",
    "    ])\n",
    "    models['BorderlineSMOTE'].fit(X_train, y_train)\n",
    "    print(\"        Complete\")\n",
    "except Exception as e:\n",
    "    print(f\"        Error: {e}\")\n",
    "\n",
    "# STRATEGY 2: SMOTEENN (SMOTE + Edited Nearest Neighbors)\n",
    "print(\"   [2/6] SMOTEENN + Enhanced Stacking...\")\n",
    "try:\n",
    "    smoteenn = SMOTEENN(random_state=42)\n",
    "    stacking_2 = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('xgb', get_xgb_model(2.0)),\n",
    "            ('lgbm', get_lgb_model()),\n",
    "            ('cat', get_cat_model()),\n",
    "            ('rf', get_rf_model())\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(\n",
    "            class_weight='balanced', \n",
    "            max_iter=2000, \n",
    "            C=0.05,\n",
    "            penalty='l2'\n",
    "        ),\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    models['SMOTEENN'] = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', smoteenn),\n",
    "        ('stacker', stacking_2)\n",
    "    ])\n",
    "    models['SMOTEENN'].fit(X_train, y_train)\n",
    "    print(\"        Complete\")\n",
    "except Exception as e:\n",
    "    print(f\"        Error: {e}\")\n",
    "\n",
    "# STRATEGY 3: Hybrid Undersampling + ADASYN\n",
    "print(\"   [3/6] Hybrid (Undersample + ADASYN) + Stacking...\")\n",
    "try:\n",
    "    rus = RandomUnderSampler(sampling_strategy=0.4, random_state=42)\n",
    "    adasyn = ADASYN(random_state=42, n_neighbors=7)\n",
    "    stacking_3 = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('xgb', get_xgb_model(1.2)),\n",
    "            ('lgbm', get_lgb_model()),\n",
    "            ('cat', get_cat_model())\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(\n",
    "            class_weight='balanced', \n",
    "            max_iter=2000, \n",
    "            C=0.1\n",
    "        ),\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    models['Hybrid'] = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('undersampler', rus),\n",
    "        ('oversampler', adasyn),\n",
    "        ('stacker', stacking_3)\n",
    "    ])\n",
    "    models['Hybrid'].fit(X_train, y_train)\n",
    "    print(\"        Complete\")\n",
    "except Exception as e:\n",
    "    print(f\"        Error: {e}\")\n",
    "\n",
    "# STRATEGY 4: Weighted Voting (No resampling, pure weighting)\n",
    "print(\"   [4/6] Weighted Voting (No Resampling)...\")\n",
    "try:\n",
    "    voting = VotingClassifier(\n",
    "        estimators=[\n",
    "            ('xgb', get_xgb_model(2.5)),\n",
    "            ('lgbm', get_lgb_model()),\n",
    "            ('cat', get_cat_model())\n",
    "        ],\n",
    "        voting='soft',\n",
    "        weights=[2, 1, 1],  # Give more weight to XGB\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    models['WeightedVoting'] = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('voter', voting)\n",
    "    ])\n",
    "    models['WeightedVoting'].fit(X_train, y_train)\n",
    "    print(\"        Complete\")\n",
    "except Exception as e:\n",
    "    print(f\"        Error: {e}\")\n",
    "\n",
    "# STRATEGY 5: SMOTETomek + Simple Stacking\n",
    "print(\"   [5/6] SMOTETomek + 3-Model Stacking...\")\n",
    "try:\n",
    "    smotetomek = SMOTETomek(random_state=42)\n",
    "    stacking_5 = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('xgb', get_xgb_model(1.8)),\n",
    "            ('lgbm', get_lgb_model()),\n",
    "            ('cat', get_cat_model())\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(\n",
    "            class_weight='balanced',\n",
    "            max_iter=2000,\n",
    "            C=0.08,\n",
    "            penalty='l1',\n",
    "            solver='saga'\n",
    "        ),\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    models['SMOTETomek'] = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', smotetomek),\n",
    "        ('stacker', stacking_5)\n",
    "    ])\n",
    "    models['SMOTETomek'].fit(X_train, y_train)\n",
    "    print(\"        Complete\")\n",
    "except Exception as e:\n",
    "    print(f\"        Error: {e}\")\n",
    "\n",
    "# STRATEGY 6: ADASYN + 4-Model Deep Stacking\n",
    "print(\"   [6/6] ADASYN + 4-Model Deep Stacking...\")\n",
    "try:\n",
    "    adasyn_deep = ADASYN(random_state=42, n_neighbors=10)\n",
    "    stacking_6 = StackingClassifier(\n",
    "        estimators=[\n",
    "            ('xgb1', get_xgb_model(1.5)),\n",
    "            ('xgb2', get_xgb_model(2.0)),\n",
    "            ('lgbm', get_lgb_model()),\n",
    "            ('cat', get_cat_model())\n",
    "        ],\n",
    "        final_estimator=LogisticRegression(\n",
    "            class_weight='balanced',\n",
    "            max_iter=2000,\n",
    "            C=0.03,\n",
    "            penalty='elasticnet',\n",
    "            solver='saga',\n",
    "            l1_ratio=0.5\n",
    "        ),\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    models['ADASYN_Deep'] = ImbPipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('sampler', adasyn_deep),\n",
    "        ('stacker', stacking_6)\n",
    "    ])\n",
    "    models['ADASYN_Deep'].fit(X_train, y_train)\n",
    "    print(\"        Complete\")\n",
    "except Exception as e:\n",
    "    print(f\"        Error: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# 7. COMPREHENSIVE EVALUATION\n",
    "# ============================================================\n",
    "print(\"\\n[7/8] Evaluating all models...\\n\")\n",
    "\n",
    "def evaluate_with_threshold_optimization(model, X_val, y_val, model_name):\n",
    "    \"\"\"Evaluate model with optimal threshold for F1-score\"\"\"\n",
    "    try:\n",
    "        y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        # Find optimal threshold\n",
    "        precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "        f1_scores = 2 * (precision * recall) / (precision + recall + 1e-9)\n",
    "        best_idx = np.argmax(f1_scores[:-1])\n",
    "        best_threshold = thresholds[best_idx]\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred_opt = (y_pred_proba >= best_threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        f1_opt = f1_score(y_val, y_pred_opt)\n",
    "        cm = confusion_matrix(y_val, y_pred_opt)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        \n",
    "        precision_opt = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall_opt = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        \n",
    "        print(f\"   {model_name:20s} | F1: {f1_opt:.4f} | P: {precision_opt:.4f} | R: {recall_opt:.4f} | Thresh: {best_threshold:.4f}\")\n",
    "        \n",
    "        return {\n",
    "            'model': model_name,\n",
    "            'f1_score': f1_opt,\n",
    "            'precision': precision_opt,\n",
    "            'recall': recall_opt,\n",
    "            'accuracy': accuracy_score(y_val, y_pred_opt),\n",
    "            'roc_auc': roc_auc_score(y_val, y_pred_proba),\n",
    "            'threshold': best_threshold,\n",
    "            'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn,\n",
    "            'model_obj': model\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"   {model_name:20s} | Error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"   \" + \"=\"*75)\n",
    "print(f\"   {'Model':<20s} | {'F1-Score':<10s} | {'Precision':<10s} | {'Recall':<10s} | {'Threshold'}\")\n",
    "print(\"   \" + \"=\"*75)\n",
    "\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    result = evaluate_with_threshold_optimization(model, X_val, y_val, name)\n",
    "    if result:\n",
    "        results.append(result)\n",
    "\n",
    "# ============================================================\n",
    "# 8. FINAL RESULTS & RECOMMENDATIONS\n",
    "# ============================================================\n",
    "print(\"\\n[8/8] Final Results\\n\")\n",
    "print(\"=\"*70)\n",
    "print(\"  F1-SCORE RANKING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('f1_score', ascending=False)\n",
    "    \n",
    "    print(f\"\\n{'Rank':<6} {'Model':<22} {'F1':<10} {'Precision':<10} {'Recall':<10} {'ROC-AUC':<10}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    for i, row in enumerate(results_df.itertuples(), 1):\n",
    "        medal = \"\" if i == 1 else \"\" if i == 2 else \"\" if i == 3 else \"  \"\n",
    "        print(f\"{medal} {i:<4} {row.model:<22} {row.f1_score:<10.4f} {row.precision:<10.4f} {row.recall:<10.4f} {row.roc_auc:<10.4f}\")\n",
    "    \n",
    "    # Best model details\n",
    "    best = results_df.iloc[0]\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\" CHAMPION MODEL: {best['model']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"\\n Performance Metrics:\")\n",
    "    print(f\"   F1-Score:        {best['f1_score']:.4f}\")\n",
    "    print(f\"   Precision:       {best['precision']:.4f}\")\n",
    "    print(f\"   Recall:          {best['recall']:.4f}\")\n",
    "    print(f\"   Accuracy:        {best['accuracy']:.4f}\")\n",
    "    print(f\"   ROC-AUC:         {best['roc_auc']:.4f}\")\n",
    "    print(f\"   Optimal Thresh:  {best['threshold']:.4f}\")\n",
    "    \n",
    "    print(f\"\\n Confusion Matrix:\")\n",
    "    print(f\"                Predicted\")\n",
    "    print(f\"              Alive  Failed\")\n",
    "    print(f\"   Actual Alive  {best['tn']:5d}  {best['fp']:5d}\")\n",
    "    print(f\"   Actual Failed {best['fn']:5d}  {best['tp']:5d}\")\n",
    "    \n",
    "    # Calculate improvement\n",
    "    baseline_f1 = 0.4314\n",
    "    improvement = ((best['f1_score'] - baseline_f1) / baseline_f1) * 100\n",
    "    \n",
    "    print(f\"\\n Performance vs Baseline:\")\n",
    "    print(f\"   Baseline F1:     {baseline_f1:.4f}\")\n",
    "    print(f\"   Current F1:      {best['f1_score']:.4f}\")\n",
    "    if improvement > 0:\n",
    "        print(f\"   Improvement:     +{improvement:.1f}% \")\n",
    "    else:\n",
    "        print(f\"   Change:          {improvement:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n Key Insights:\")\n",
    "    print(f\"    Detected {best['tp']} out of {best['tp'] + best['fn']} failures ({best['recall']*100:.1f}% recall)\")\n",
    "    print(f\"    {best['precision']*100:.1f}% of predicted failures were correct\")\n",
    "    print(f\"    Use threshold = {best['threshold']:.4f} for optimal F1-score\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"Pipeline complete! Models ready for production use.\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2c850d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
